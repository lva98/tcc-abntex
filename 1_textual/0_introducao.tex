\chapter{Introdução}
Na contemporaneidade nota-se uma tendência das organizações em mover aplicações de escala corporativa para a Computação em Nuvem. As razões para essa ocorrência são múltiplas: alta disponibilidade e redundância, escala automática, gerenciamento integrado de \textit{data center} e fluxo de desenvolvimento \cite{Fritzsch}. Impulsionado pelo paradigma imposto pela Computação em Nuvem, a forma de arquitetar, testar, e implantar \textit{software} mudou fundamentalmente, de forma que aplicações escaláveis migram de monolíticas para distribuída em microsserviços, para se enquadrar na Computação em Nuvem.

O termo microsserviço surgiu nos últimos anos para descrever um método específico de arquitetar \textit{software} como um conjunto de serviços que são escalados e implementados independentemente \cite{FowlerMicrosservice}. No contexto de Nuvem Computacional, os microsserviços podem ser utilizados na forma de contêineres, que são unidades de \textit{software} autônomas que encapsulam aplicações e todas suas dependências. No contêiner, os recursos de um nó computacional são compartilhados sem a necessidade da instalação e configuração de dependências. Isso permite que os provedores de estrutura virtual instanciem, realoquem e otimizem suas aplicações de forma mais flexível com desempenho virtual próximo ao \textit{bare metal}. Além de todos esses benefícios, os contêineres oferecem isolamento a nível de sistema operacional, assim, no ponto de vista do usuário, o contêiner executa um sistema operacional independente \cite{Fazio2016, Assuno}. 

A virtualização de contêineres baseada no sistema operacional GNU/Linux é a mais popular, sendo denominada de \textit{Linux container virtualization} (LCV). Gerenciadores LCV encontrados na atualidade são \textit{Docker}, \textit{Linux Containers} (LXC) e \textit{OpenVZ} \cite{Fazio2016}. Entre os \textit{softwares} de virtualização de microsserviços baseados em contêineres, destaca-se \textit{Docker}. Essa tecnologia proporciona funcionalidades além da capacidade de virtualização, pois facilita o processo de criação, construção e controle de versão de imagens de contêineres \cite{Redhat}.
%
Existem ferramentas que gerenciam e coordenam o escalonamento de contêineres em \textit{clusters}. Para a administração de contêineres \textit{Docker} é comum o uso de tecnologias como \textit{Docker Swarm} e \ac{K8}. Ao utilizar essas ferramentas, o usuário possuirá controle da infraestrutura de maneira simplificada e será capaz de criar, alterar e remover contêineres de forma eficiente. De acordo com \citeonline{Rodriguez2018}, tecnologias como \textit{Docker Swarm} e \textit{Kubernetes} são classificados como orquestradores de contêineres. Os orquestradores atuais, além de oferecer estrutura de controle do ambiente de virtualização, também são responsáveis pelo escalonamento, replicação e alta disponibilidade das aplicações. 

Para \citeonline{Arundel}, o \textit{Kubernetes} é considerado o Sistema Operacional das Nuvens Computacionais, sendo o sistema de orquestração de contêineres padrão no mercado. Para isso, o \textit{Kubernetes} oferece um ambiente robusto para implantação de sistemas voltados para Nuvem. As principais características do orquestrador são: escala automática de cargas de trabalho, balanceamento de carga, escalonamento por agrupamento ou espalhamento, e monitoramento do \textit{cluster}.
%
O \textit{Kubernetes} é um sistema de orquestração que agrupa contêineres em \textit{pods}. \textit{Pod} é um grupo com um ou mais contêineres que compartilham recursos de armazenamento e rede. Dessa forma, contêineres dispostos em um mesmo \textit{pod} são escalonados e executados simultaneamente \cite{Google}. Ou seja, todas as dependências que a aplicação conteinerizada necessita serão lançadas e agrupadas ao mesmo tempo e \textit{pod}, respectivamente. Além disso, a \textit{Google} disponibiliza, de forma oficial, bibliotecas que utilizam \textit{Application Programming Interface} (API) do \textit{cluster} \textit{Kubernetes}  para as principais linguagens de programação (\textit{e.g.}, \textit{.NET}, \textit{Python}, \textit{Java}, \textit{Go}, \textit{JavaScript}, \textit{Haskell}). Por meio da API é possível obter o estado do \textit{cluster}, configurar, lançar e escalonar \textit{pods} \textit{Kubernetes} \cite{KubernetesAPI}.

Para realizar o escalonamento dos \textit{pods}, o \textit{kube-scheduler} executa um fluxo de operações que são separadas em duas categorias, sendo elas, filtragem e ranqueamento. Em resumo, a filtragem consiste em investigar \textit{nodes} que são capazes de executar o \textit{pod} a ser escalonado, ou seja, nessa etapa há a seleção dos \textit{nodes} do \textit{cluster} que satisfazem a solicitação de recursos do \textit{pod}. O ranqueamento, por sua vez, classifica os \textit{nodes} eleitos pela filtragem e seleciona o \textit{node} que obter a maior pontuação de acordo a solicitação de recursos do \textit{pod} \cite{Kubescheduler}.

A principal limitação do \textit{Kube-scheduler} é na etapa anterior à filtragem: o \textit{Kubernetes} utiliza um método ingênuo na escolha do próximo contêiner a ser escalonado, que consiste em escalonar de acordo com a ordem de chegada. Essa técnica também é conhecida como \textit{First-Come-First-Serverd} (FCFS) ou \textit{First-In-First-Out} (FIFO)~\cite{Ye2007}. A limitação do \textit{Kube-scheduler}, na utilização do \textit{FCFS}, reflete diretamente na escalabilidade do problema, que por consequência, degrada o \textit{makespan} (tempo total) e tempo de espera de escalonamento. Alguns motivos são elencados para defender a escolha do \textit{FCFS}, por exemplo, garantia da ausência de inanição e simples implementação algorítmica. Embora exista o consenso que há espaço de melhoria algorítmica, substituir essa técnica de escalonamento por um algoritmo refinado é uma tarefa complexa \cite{CarastanSantos2019}.

Para o desenvolvimento de uma arquitetura distribuída de escalonamento há a necessidade de elencar algumas métricas para validação da abordagem. O presente trabalho considerou de forma primordial duas métricas relacionadas com o desempenho de escalonamento: tempo de espera de escalonamento e \textit{makespan}. O tempo de espera, como a denominação sugere, é o tempo decorrido do contêiner na fila de espera até ser escalonado, considerado um \textit{delay} do momento em que o contêiner foi submetido à plataforma até sua execução. O \textit{makespan}, uma métrica diretamente proporcional ao tempo de espera, reflete no tempo total que o contêiner permaneceu na plataforma, ou seja, do momento em que foi submetido até a sua finalização. Além dessas duas métricas será analisado o comportamento do \textit{slowdown} na arquitetura distribuída proposta. O propósito do \textit{slowdown} é estabelecer proporção entre tempo de espera de um trabalho em relação ao seu tempo de processamento. As métricas aqui apresentadas, de forma resumida, são melhor exploradas na Seção 2.4.1.

\section{Objetivos}
\label{obj}

\subsection{Objetivo geral}
\label{objgeral}

Os objetivos gerais deste trabalho refletiram no desenvolvimento de um escalonador distribuído para \textit{Kubernetes}, utilização da abordagem de microsserviços na implementação e validação da abordagem diante as métricas de otimização: tempo de espera de escalonamento e \textit{makespan}.

\subsection{Objetivos específicos}
\label{objesp}

\begin{itemize}
    \item Compreender \textit{Kubernetes};
    \item Revisar escalonamento descentralizado (utilizando particionamento e duplicação de trabalho);
    \item Revisar orquestração de contêineres;
    \item Revisar arquitetura de microsserviços;
    \item Desenvolver um escalonador distribuído baseado em microsserviços;
    \item Analisar o desempenho do escalonador proposto em relação ao tempo de espera e \textit{makespan}; e
    \item Analisar o comportamento do \textit{slowdown} em arquitetura distribuída.
\end{itemize}

\newpage
\subsection{Organização do texto}

O presente trabalho está organizado a partir da seguinte estrutura: o Capítulo 2 aborda uma revisão de literatura acerca do tema proposto, desde revisão de Computação em Nuvem até alcançar as especificidades do projeto revisando \textit{Kubernetes}, microsserviços e escalonamento de tarefas. Ao fim do Capítulo 2 são apresentados os trabalhos relacionados sobre escalonamento de contêineres com diferentes objetivos. No Capítulo 3 é detalhado a proposta distribuída, ao passo que o Capítulo 4 refere-se ao plano de teste do trabalho proposto. No capítulo 5 será feita análise dos resultados coletados de acordo com o plano de testes. Por fim, o Capítulo 6 conclui o presente trabalho de conclusão de curso e abre discussão para melhorias futuras. 